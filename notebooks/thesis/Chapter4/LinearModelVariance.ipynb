{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e0efce-6a46-44c6-8945-804d72b55b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import *\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.othermod.betareg import BetaModel\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "\n",
    "pio.renderers.default = \"iframe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c53298e-9414-4908-9ccc-c21ca98a8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/data/saturation/n_craters_stop_condition_20230918\"\n",
    "\n",
    "ivs = [\n",
    "    \"slope\",\n",
    "    \"effective_radius_multiplier\",\n",
    "    \"r_stat_multiplier\",\n",
    "    \"min_rim_percentage\",\n",
    "    \"exp_mean_r\",\n",
    "    \"z\",\n",
    "    \"za\",\n",
    "    \"n_craters_in_study_region\",\n",
    "    \"areal_density\",\n",
    "    \"areal_density_overlap_2\",\n",
    "    \"areal_density_overlap_3\",\n",
    "    \"center_to_center_nearest_neighbor_distance_mean\",\n",
    "    \"center_to_center_nearest_neighbor_distance_stdev\",\n",
    "    \"center_to_center_nearest_neighbor_distance_min\",\n",
    "    \"center_to_center_nearest_neighbor_distance_max\",\n",
    "    \"radius_mean\",\n",
    "    \"radius_stdev\",\n",
    "]\n",
    "\n",
    "measured_ivs = [\n",
    "    \"slope\",\n",
    "    \"z\",\n",
    "    \"za\",\n",
    "    \"exp_mean_r\",\n",
    "    \"n_craters_in_study_region\",\n",
    "    \"areal_density\",\n",
    "    \"areal_density_overlap_2\",\n",
    "    \"areal_density_overlap_3\",\n",
    "    \"center_to_center_nearest_neighbor_distance_mean\",\n",
    "    \"center_to_center_nearest_neighbor_distance_stdev\",\n",
    "    \"center_to_center_nearest_neighbor_distance_min\",\n",
    "    \"center_to_center_nearest_neighbor_distance_max\",\n",
    "    \"radius_mean\",\n",
    "    \"radius_stdev\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5673fd7a-2f17-4e8b-b1a1-246918e3817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distribution_mean(slope: float,\n",
    "                                x_min: float,\n",
    "                                x_max: float):\n",
    "    scaling = 1 / (1 - (x_min / x_max)**slope)\n",
    "    return (scaling * slope / (1 - slope)) * (x_max*(x_min/x_max)**slope - x_min)\n",
    "    \n",
    "\n",
    "def fix_up_df(df: pd.DataFrame):\n",
    "    df[\"z\"] = df.z.fillna(0)\n",
    "    df[\"za\"] = df.za.fillna(0)\n",
    "    df[\"x_min\"] = 5\n",
    "    df[\"x_max\"] = 1000\n",
    "    df[\"exp_mean_r\"] = calculate_distribution_mean(df.slope, df.x_min, df.x_max)\n",
    "    df[\"log_n_craters_added_in_study_region\"] = np.log10(df.n_craters_added_in_study_region)\n",
    "    df[\"center_to_center_nearest_neighbor_distance_mean_slope\"] = df.center_to_center_nearest_neighbor_distance_mean * df.slope \n",
    "    df[\"log_center_to_center_nearest_neighbor_distance_mean_slope\"] = np.log10(df.center_to_center_nearest_neighbor_distance_mean) * df.slope \n",
    "    for x in ivs:\n",
    "        df[f\"log_{x}\"] = np.log10(1 + df[x])\n",
    "    df[\"log_stdev_N\"] = np.log10(np.sqrt(df.variance))\n",
    "    \n",
    "    return df[df.isna().sum(axis=1) == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f00a09-629a-4aac-84bc-047277229ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_simulations = 1000\n",
    "# sample_size = 100\n",
    "\n",
    "# train_df = pd.read_parquet(f\"{base_path}/train_{n_simulations}_{sample_size}.parquet\")\n",
    "# train_df = fix_up_df(train_df)\n",
    "\n",
    "# test_df = pd.read_parquet(f\"{base_path}/test_{n_simulations}_{sample_size}.parquet\")\n",
    "# test_df = fix_up_df(test_df)\n",
    "\n",
    "# metric = \"post_saturation_n_craters_in_study_region_percentile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dccceb41-f899-4136-a390-f1c81c0e8360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mason/code/saturation/venv_311/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log10\n",
      "\n",
      "/home/mason/code/saturation/venv_311/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log10\n",
      "\n",
      "/home/mason/code/saturation/venv_311/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log10\n",
      "\n",
      "/home/mason/code/saturation/venv_311/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in log10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_parquet(f\"{base_path}/train_with_variance.parquet\")\n",
    "train_df = fix_up_df(train_df)\n",
    "\n",
    "test_df = pd.read_parquet(f\"{base_path}/test_with_variance.parquet\")\n",
    "test_df = fix_up_df(test_df)\n",
    "\n",
    "metric = \"log_stdev_N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01885dcb-5013-44ff-a80f-e7fa0e975dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ffa6d6e-a8e4-4e83-8844-19ebf9d2a282",
   "metadata": {},
   "source": [
    "### Linear regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ecc83d9-94e9-4aa4-b443-f7f0431bb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_report_statsmodels_glm_model(family: sm.families.Family,\n",
    "                                         X_train,\n",
    "                                         y_train,\n",
    "                                         X_test,\n",
    "                                         y_test,\n",
    "                                         model_name):\n",
    "    model = sm.GLM(y_train, X_train, family=family).fit()\n",
    "    print(model.summary())\n",
    "\n",
    "    y_pred = model.predict(X_train)\n",
    "    rmse = mean_squared_error(y_pred, y_train, squared=False)\n",
    "    mape = mean_absolute_percentage_error(y_pred, y_train)\n",
    "    mae = mean_absolute_error(y_pred, y_train)\n",
    "    print(f\"***** {model_name} *****\")\n",
    "    print(f\"Train RMSE: {rmse:.4f}, Train MAE: {mae:.4f}, Train MAPE: {mape:.4f}\")\n",
    "\n",
    "    residuals = y_train - y_pred\n",
    "    plt.hist(residuals, bins=50)\n",
    "    plt.show()\n",
    "\n",
    "    ks_norm_p = stats.kstest(residuals, cdf=stats.norm.cdf).pvalue\n",
    "    ad_result = stats.anderson(residuals, dist=\"norm\")\n",
    "    print(f\"KS test p-value on training residuals: {ks_norm_p:.3f}\")\n",
    "    print(f\"AD test on training residuals: {ad_result.statistic:.3f}, critical values: {ad_result.critical_values}, significance levels: {ad_result.significance_level}\")\n",
    "\n",
    "    print(f\"*** Test set\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_pred, y_test, squared=False)\n",
    "    mape = mean_absolute_percentage_error(y_pred, y_test)\n",
    "    mae = mean_absolute_error(y_pred, y_test)\n",
    "    print(f\"Test RMSE: {rmse:.4f}, Test MAE: {mae:.4f}, Test MAPE: {mape:.4f}\")\n",
    "\n",
    "    y_pred_mean_model = [y_train.mean()] * len(y_test)\n",
    "    rmse = mean_squared_error(y_pred_mean_model, y_test, squared=False)\n",
    "    mape = mean_absolute_percentage_error(y_pred_mean_model, y_test)\n",
    "    mae = mean_absolute_error(y_pred_mean_model, y_test)\n",
    "    print(f\"Mean model: RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4b7d47-a2db-443d-b0ac-ccd2536d8217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_report_statsmodels_model(model_creator: Callable[[pd.DataFrame, pd.DataFrame], Any],\n",
    "                                     X_train,\n",
    "                                     y_train,\n",
    "                                     X_test,\n",
    "                                     y_test,\n",
    "                                     model_name,\n",
    "                                     transform=lambda x: x,\n",
    "                                     inverse_transform=lambda x: x):\n",
    "    y_train_transformed = transform(y_train)\n",
    "    \n",
    "    model = model_creator(y_train_transformed, X_train).fit()\n",
    "    print(model.summary())\n",
    "\n",
    "    y_pred = inverse_transform(model.predict(X_train))\n",
    "    rmse = mean_squared_error(y_pred, y_train, squared=False)\n",
    "    mape = mean_absolute_percentage_error(y_pred, y_train)\n",
    "    mae = mean_absolute_error(y_pred, y_train)\n",
    "    print(f\"***** {model_name} *****\")\n",
    "    print(f\"Train RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.4f}\")\n",
    "\n",
    "    residuals = y_train - y_pred\n",
    "    plt.hist(residuals, bins=50)\n",
    "    plt.show()\n",
    "\n",
    "    ks_norm_p = stats.kstest(residuals, cdf=stats.norm.cdf).pvalue\n",
    "    ad_result = stats.anderson(residuals, dist=\"norm\")\n",
    "    print(f\"KS test p-value on training residuals: {ks_norm_p:.3f}\")\n",
    "    print(f\"AD test on training residuals: {ad_result.statistic:.3f}, critical values: {ad_result.critical_values}, significance levels: {ad_result.significance_level}\")\n",
    "\n",
    "    print(f\"*** Test set\")\n",
    "    y_pred = inverse_transform(model.predict(X_test))\n",
    "    rmse = mean_squared_error(y_pred, y_test, squared=False)\n",
    "    mape = mean_absolute_percentage_error(y_pred, y_test)\n",
    "    mae = mean_absolute_error(y_pred, y_test)\n",
    "    print(f\"Test RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.4f}\")\n",
    "\n",
    "    y_pred_mean_model = [y_train.mean()] * len(y_test)\n",
    "    rmse = mean_squared_error(y_pred_mean_model, y_test, squared=False)\n",
    "    mape = mean_absolute_percentage_error(y_pred_mean_model, y_test)\n",
    "    mae = mean_absolute_error(y_pred_mean_model, y_test)\n",
    "    print(f\"Mean model: RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65a524f-584a-4c80-b04a-a119056261dc",
   "metadata": {},
   "source": [
    "### Linear Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1189b66-188d-49f3-a5b6-30892ac6d03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            log_stdev_N   R-squared:                       0.637\n",
      "Model:                            OLS   Adj. R-squared:                  0.637\n",
      "Method:                 Least Squares   F-statistic:                     8688.\n",
      "Date:                Thu, 12 Oct 2023   Prob (F-statistic):               0.00\n",
      "Time:                        16:13:34   Log-Likelihood:             1.2860e+05\n",
      "No. Observations:              143813   AIC:                        -2.571e+05\n",
      "Df Residuals:                  143783   BIC:                        -2.568e+05\n",
      "Df Model:                          29                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=============================================================================================================================\n",
      "                                                                coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "const                                                        -0.4919      0.000  -1884.890      0.000      -0.492      -0.491\n",
      "log_center_to_center_nearest_neighbor_distance_mean_slope    -0.3510      0.006    -60.733      0.000      -0.362      -0.340\n",
      "slope                                                         1.2332      0.036     34.061      0.000       1.162       1.304\n",
      "z                                                            -0.0345      0.003    -10.394      0.000      -0.041      -0.028\n",
      "za                                                           -0.0454      0.004    -10.870      0.000      -0.054      -0.037\n",
      "exp_mean_r                                                   -0.0086      0.008     -1.061      0.288      -0.024       0.007\n",
      "n_craters_in_study_region                                    -0.0812      0.005    -17.020      0.000      -0.091      -0.072\n",
      "areal_density                                                -0.9511      0.016    -60.309      0.000      -0.982      -0.920\n",
      "areal_density_overlap_2                                       0.7477      0.031     23.889      0.000       0.686       0.809\n",
      "areal_density_overlap_3                                      -1.9902      0.063    -31.556      0.000      -2.114      -1.867\n",
      "center_to_center_nearest_neighbor_distance_mean               0.1035      0.003     30.531      0.000       0.097       0.110\n",
      "center_to_center_nearest_neighbor_distance_stdev             -0.0279      0.002    -11.255      0.000      -0.033      -0.023\n",
      "center_to_center_nearest_neighbor_distance_min               -0.0216      0.001    -31.734      0.000      -0.023      -0.020\n",
      "center_to_center_nearest_neighbor_distance_max                0.0104      0.001      9.702      0.000       0.008       0.012\n",
      "radius_mean                                                   0.0266      0.002     10.661      0.000       0.022       0.031\n",
      "radius_stdev                                                 -0.1342      0.007    -19.014      0.000      -0.148      -0.120\n",
      "log_slope                                                    -1.1225      0.050    -22.288      0.000      -1.221      -1.024\n",
      "log_z                                                        -0.0426      0.001    -44.815      0.000      -0.045      -0.041\n",
      "log_za                                                        0.3157      0.006     54.801      0.000       0.304       0.327\n",
      "log_exp_mean_r                                               -0.4606      0.023    -19.818      0.000      -0.506      -0.415\n",
      "log_n_craters_in_study_region                                 0.5251      0.039     13.351      0.000       0.448       0.602\n",
      "log_areal_density                                             0.7456      0.016     47.215      0.000       0.715       0.777\n",
      "log_areal_density_overlap_2                                  -0.7080      0.031    -23.090      0.000      -0.768      -0.648\n",
      "log_areal_density_overlap_3                                   1.9859      0.063     31.314      0.000       1.862       2.110\n",
      "log_center_to_center_nearest_neighbor_distance_mean           0.6723      0.032     20.998      0.000       0.610       0.735\n",
      "log_center_to_center_nearest_neighbor_distance_stdev          0.1289      0.006     20.138      0.000       0.116       0.141\n",
      "log_center_to_center_nearest_neighbor_distance_min            0.0107      0.001     16.218      0.000       0.009       0.012\n",
      "log_center_to_center_nearest_neighbor_distance_max           -0.0031      0.001     -2.814      0.005      -0.005      -0.001\n",
      "log_radius_mean                                               0.1313      0.012     10.520      0.000       0.107       0.156\n",
      "log_radius_stdev                                              0.0857      0.007     12.232      0.000       0.072       0.099\n",
      "==============================================================================\n",
      "Omnibus:                    57397.236   Durbin-Watson:                   1.972\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          3956462.299\n",
      "Skew:                          -1.077   Prob(JB):                         0.00\n",
      "Kurtosis:                      28.605   Cond. No.                     1.48e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.48e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "***** LM No Interactions *****\n",
      "Train RMSE: 0.0989, MAE: 0.0562, MAPE: 0.1252\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS test p-value on training residuals: 0.000\n",
      "AD test on training residuals: 7459.027, critical values: [0.576 0.656 0.787 0.918 1.092], significance levels: [15.  10.   5.   2.5  1. ]\n",
      "*** Test set\n",
      "Test RMSE: 0.0987, MAE: 0.0561, MAPE: 0.1119\n",
      "Mean model: RMSE: 0.1634, MAE: 0.1039, MAPE: 0.2113\n"
     ]
    }
   ],
   "source": [
    "# Simple LM, all IVs\n",
    "metric = \"log_stdev_N\"\n",
    "\n",
    "exclude = {}\n",
    "features = [\"log_center_to_center_nearest_neighbor_distance_mean_slope\"] + [x for x in measured_ivs if x not in exclude] + [f\"log_{x}\" for x in measured_ivs if f\"log_{x}\" not in exclude]\n",
    "# features = [\n",
    "#     \"log_center_to_center_nearest_neighbor_distance_mean_slope\",\n",
    "#     \"slope\",\n",
    "#     \"log_center_to_center_nearest_neighbor_distance_mean\"\n",
    "# ]\n",
    "\n",
    "xtr = train_df.reset_index().copy()\n",
    "xte = test_df.reset_index().copy()\n",
    "\n",
    "X_train = xtr[features]\n",
    "X_test = xte[features]\n",
    "\n",
    "y_train = xtr[metric]\n",
    "y_test = xte[metric]\n",
    "\n",
    "standard_scaler = sklearn.preprocessing.StandardScaler()\n",
    "X_train = standard_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=standard_scaler.get_feature_names_out())\n",
    "\n",
    "poly_transform = sklearn.preprocessing.PolynomialFeatures(degree=1, include_bias=False)\n",
    "X_train = poly_transform.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "X_test = pd.DataFrame(standard_scaler.transform(X_test), columns=standard_scaler.get_feature_names_out())\n",
    "X_test = poly_transform.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "model = fit_and_report_statsmodels_model(lambda y, x: sm.OLS(y, x),\n",
    "                                         sm.add_constant(X_train),\n",
    "                                         y_train,\n",
    "                                         sm.add_constant(X_test),\n",
    "                                         y_test,\n",
    "                                         \"LM No Interactions\",\n",
    "                                         transform=lambda x: x,\n",
    "                                         inverse_transform=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331416f9-763f-4e89-b76a-9e097bc36492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ce49bc-5da5-47fa-9eb1-62a5cafd3a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6821ea3-1231-47bc-b3a1-137f0bb1de2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e08553-0bb7-4d8f-aad1-7f3e87714f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c57410-7f6c-4ae8-9723-0c59efcc3c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple LM, all IVs\n",
    "\n",
    "metric = \"log_std\"\n",
    "\n",
    "exclude = {\n",
    "    \"r_stat_multiplier\", # p value\n",
    "    \"center_to_center_nearest_neighbor_distance_stdev\", # p value\n",
    "    \"z\", # p value\n",
    "    \"areal_density_overlap_3\",\n",
    "    \"areal_density_overlap_2\",\n",
    "    \"log_areal_density_overlap_2\",\n",
    "    \"center_to_center_nearest_neighbor_distance_mean\",\n",
    "    \"log_center_to_center_nearest_neighbor_distance_stdev\",\n",
    "    \"log_z\",\n",
    "    \"log_za\",\n",
    "    \"n_craters_in_study_region\",\n",
    "    \"log_radius_stdev\",\n",
    "    \"radius_stdev\"\n",
    "}\n",
    "features = [x for x in measured_ivs if x not in exclude] + [f\"log_{x}\" for x in measured_ivs if f\"log_{x}\" not in exclude]\n",
    "\n",
    "xtr = train_df.reset_index().copy()\n",
    "xte = test_df.reset_index().copy()\n",
    "\n",
    "X_train = xtr[features]\n",
    "X_test = xte[features]\n",
    "\n",
    "y_train = xtr[metric]\n",
    "y_test = xte[metric]\n",
    "\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=min_max_scaler.get_feature_names_out())\n",
    "\n",
    "poly_transform = sklearn.preprocessing.PolynomialFeatures(degree=1, include_bias=False)\n",
    "X_train = poly_transform.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "X_test = pd.DataFrame(min_max_scaler.transform(X_test), columns=min_max_scaler.get_feature_names_out())\n",
    "X_test = poly_transform.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "model = fit_and_report_statsmodels_model(lambda y, x: sm.OLS(y, x),\n",
    "                                         sm.add_constant(X_train),\n",
    "                                         y_train,\n",
    "                                         sm.add_constant(X_test),\n",
    "                                         y_test,\n",
    "                                         \"LM No Interactions\",\n",
    "                                         transform=lambda x: x,\n",
    "                                         inverse_transform=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f972890a-0163-424f-9d3c-0df568525590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ended here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d17dbd9-442f-4b49-bb72-cb4eddf0ddc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a4b757-e576-44e4-a080-520960363590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb2836a-0e1a-44ec-bf9b-1e8fc00dfe55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f36ec4-3cb9-477f-bc17-d8b5bf393562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89abb4-51c3-4423-8b77-2ef7bd3906df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple model, all IVs, GLM w/binomial and logit link\n",
    "\n",
    "metric = \"post_saturation_n_craters_in_study_region_percentile\"\n",
    "exclude = {\n",
    "    \"log_z\",\n",
    "    \"log_za\",\n",
    "    \"z\",\n",
    "    \"za\",\n",
    "}\n",
    "# features = [x for x in measured_ivs if x not in exclude]\n",
    "features = [f\"log_{x}\" for x in measured_ivs if f\"log_{x}\" not in exclude]\n",
    "\n",
    "xtr = train_df[train_df[metric] > 0].reset_index().copy()\n",
    "xte = test_df[test_df[metric] > 0].reset_index().copy()\n",
    "\n",
    "X_train = xtr[features]\n",
    "X_test = xte[features]\n",
    "\n",
    "y_train = xtr[metric]\n",
    "y_test = xte[metric]\n",
    "\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=min_max_scaler.get_feature_names_out())\n",
    "\n",
    "poly_transform = sklearn.preprocessing.PolynomialFeatures(degree=1, include_bias=False)\n",
    "X_train = poly_transform.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "X_test = pd.DataFrame(min_max_scaler.transform(X_test), columns=min_max_scaler.get_feature_names_out())\n",
    "X_test = poly_transform.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "model = fit_and_report_statsmodels_model(lambda y, x: sm.GLM(y, x, family=sm.families.Binomial(link=sm.families.links.Logit())),\n",
    "                                         sm.add_constant(X_train),\n",
    "                                         y_train,\n",
    "                                         sm.add_constant(X_test),\n",
    "                                         y_test,\n",
    "                                         \"LM No Interactions\",\n",
    "                                         transform=lambda x: x,\n",
    "                                         inverse_transform=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453a9c33-dd0d-4e44-b018-4c2b621cae46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9492a75-d3f8-4d8d-9581-bb95d651aa91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed86422-2135-41cb-aa6a-946ce3a05706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta regression model\n",
    "\n",
    "metric = \"information_remaining\"\n",
    "\n",
    "# features = [\"slope\", \"log_areal_density\", \"log_center_to_center_nearest_neighbor_distance_mean\", \"log_center_to_center_nearest_neighbor_distance_min\", \"log_rim_to_rim_nearest_neighbor_distance_mean\", \"log_n_craters_in_study_region\"]\n",
    "# features = [\"log_center_to_center_nearest_neighbor_distance_stdev\", \"min_rim_percentage\", \"effective_radius_multiplier\", \"log_center_to_center_nearest_neighbor_distance_mean\", \"destruction\", \"log_areal_density\", \"log_areal_density_overlap_2\", \"log_areal_density_overlap_3\", \"log_center_to_center_nearest_neighbor_distance_max\", \"log_n_craters_in_study_region\", \"slope\"]\n",
    "# features = [\"slope\", \"log_center_to_center_nearest_neighbor_distance_mean\", \"destruction\", \"areal_density\", \"areal_density_overlap_2\", \"areal_density_overlap_3\"]\n",
    "\n",
    "features = [\n",
    "    \"slope\",\n",
    "    # \"effective_radius_multiplier\",\n",
    "    # \"r_stat_multiplier\",\n",
    "    # \"min_rim_percentage\",\n",
    "    \"z\",\n",
    "    \"za\",\n",
    "    \"log_n_craters_in_study_region\",\n",
    "    \"areal_density\",\n",
    "    \"areal_density_overlap_2\",\n",
    "    # \"areal_density_overlap_3\",\n",
    "    \"log_center_to_center_nearest_neighbor_distance_mean\",\n",
    "    # \"center_to_center_nearest_neighbor_distance_stdev\",\n",
    "    # \"log_center_to_center_nearest_neighbor_distance_min\",\n",
    "    \"log_center_to_center_nearest_neighbor_distance_max\",\n",
    "    \"log_rim_to_rim_nearest_neighbor_distance_mean\",\n",
    "    # \"log_rim_to_rim_nearest_neighbor_distance_stdev\",\n",
    "    # \"log_rim_to_rim_nearest_neighbor_distance_max\",\n",
    "]\n",
    "\n",
    "xtr = train_df.reset_index().copy()\n",
    "xte = test_df.reset_index().copy()\n",
    "\n",
    "xtr = xtr[xtr[metric] < 1.0].reset_index().copy()\n",
    "xte = xte[xte[metric] < 1.0].reset_index().copy()\n",
    "\n",
    "xtr = add_destruction(xtr)\n",
    "xte = add_destruction(xte)\n",
    "\n",
    "X_train = xtr[features]\n",
    "X_test = xte[features]\n",
    "\n",
    "y_train = xtr[metric]\n",
    "y_test = xte[metric]\n",
    "\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=min_max_scaler.get_feature_names_out())\n",
    "\n",
    "poly_transform = sklearn.preprocessing.PolynomialFeatures(degree=1, include_bias=False)\n",
    "X_train = poly_transform.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "X_test = pd.DataFrame(min_max_scaler.transform(X_test), columns=min_max_scaler.get_feature_names_out())\n",
    "X_test = poly_transform.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "model = fit_and_report_statsmodels_model(lambda y, x: BetaModel(y, x),\n",
    "                                         sm.add_constant(X_train),\n",
    "                                         y_train,\n",
    "                                         sm.add_constant(X_test),\n",
    "                                         y_test,\n",
    "                                         \"LM No Interactions\",\n",
    "                                         transform=lambda x: x,\n",
    "                                         inverse_transform=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc9697a-de14-411a-9dc2-1a5a69869ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07461830-9c69-4a4e-b8dc-1d48cbaa7271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24239923-53e6-4430-a4a7-62e286bc2db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60947d53-e7c0-4035-a3a5-05c28fe96610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for when information remaining is high\n",
    "\n",
    "features = [\"slope\", \"log_areal_density\", \"log_center_to_center_nearest_neighbor_distance_mean\", \"log_center_to_center_nearest_neighbor_distance_min\", \"log_rim_to_rim_nearest_neighbor_distance_mean\", \"log_n_craters_in_study_region\"]\n",
    "\n",
    "xtr = train_df[train_df.information_remaining > 0.6].reset_index().copy()\n",
    "xte = test_df[test_df.information_remaining > 0.6].reset_index().copy()\n",
    "\n",
    "X_train = xtr[features]\n",
    "X_test = xte[features]\n",
    "\n",
    "y_train = xtr[metric]\n",
    "y_test = xte[metric]\n",
    "\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=min_max_scaler.get_feature_names_out())\n",
    "\n",
    "poly_transform = sklearn.preprocessing.PolynomialFeatures(degree=1, include_bias=False)\n",
    "X_train = poly_transform.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "X_test = pd.DataFrame(min_max_scaler.transform(X_test), columns=min_max_scaler.get_feature_names_out())\n",
    "X_test = poly_transform.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "model = fit_and_report_statsmodels_model(lambda y, x: sm.OLS(y, x),\n",
    "                                         X_train,\n",
    "                                         y_train,\n",
    "                                         X_test,\n",
    "                                         y_test,\n",
    "                                         \"LM No Interactions\",\n",
    "                                         transform=lambda x: np.log(x),\n",
    "                                         inverse_transform=lambda x: np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2240ea3-99ee-4d6d-974c-10586ca187b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for when information remaining is low\n",
    "\n",
    "features = [\"slope\", \"log_areal_density\", \"log_center_to_center_nearest_neighbor_distance_mean\", \"log_center_to_center_nearest_neighbor_distance_min\", \"log_rim_to_rim_nearest_neighbor_distance_mean\", \"log_n_craters_in_study_region\"]\n",
    "\n",
    "xtr = train_df[train_df.information_remaining < 0.4].reset_index().copy()\n",
    "xte = test_df[test_df.information_remaining < 0.4].reset_index().copy()\n",
    "\n",
    "X_train = xtr[features]\n",
    "X_test = xte[features]\n",
    "\n",
    "y_train = xtr[metric]\n",
    "y_test = xte[metric]\n",
    "\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=min_max_scaler.get_feature_names_out())\n",
    "\n",
    "poly_transform = sklearn.preprocessing.PolynomialFeatures(degree=1, include_bias=False)\n",
    "X_train = poly_transform.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "X_test = pd.DataFrame(min_max_scaler.transform(X_test), columns=min_max_scaler.get_feature_names_out())\n",
    "X_test = poly_transform.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "model = fit_and_report_statsmodels_model(lambda y, x: sm.OLS(y, x),\n",
    "                                         X_train,\n",
    "                                         y_train,\n",
    "                                         X_test,\n",
    "                                         y_test,\n",
    "                                         \"LM No Interactions\",\n",
    "                                         transform=lambda x: np.log(x),\n",
    "                                         inverse_transform=lambda x: np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a8926-20b5-4b05-ae27-85e7e6fdcbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eee687-cdc9-4ffb-b011-27da19bb7f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a1098e-385e-49c7-bcbe-3ea254f39ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ff4660-2939-4413-9364-daaecfb3069b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c93f7b-1810-4a62-96e6-c6e6a609d6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ivs #[\"za\", \"areal_density\", \"n_craters_in_study_region\"]\n",
    "\n",
    "X_train = train_df[features]\n",
    "X_test = test_df[features]\n",
    "\n",
    "y_train = train_df[metric]\n",
    "y_test = test_df[metric]\n",
    "\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=min_max_scaler.get_feature_names_out())\n",
    "\n",
    "poly_transform = sklearn.preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train = poly_transform.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "X_test = pd.DataFrame(min_max_scaler.transform(X_test), columns=min_max_scaler.get_feature_names_out())\n",
    "X_test = poly_transform.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "model = fit_and_report_statsmodels_model(lambda y, x: sm.OLS(y, x),\n",
    "                                         sm.add_constant(X_train),\n",
    "                                         y_train,\n",
    "                                         sm.add_constant(X_test),\n",
    "                                         y_test,\n",
    "                                         \"LM No Interactions\",\n",
    "                                         transform=lambda x: x,\n",
    "                                         inverse_transform=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cef8a9-44f9-4f19-b66b-a0cb57aae546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03bf1d-0f87-414a-ba21-fd5d71ffdc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = train_df[train_df[metric] < .99]\n",
    "te = test_df[test_df[metric] < .99]\n",
    "\n",
    "X_train = tr[ivs]\n",
    "X_test = te[ivs]\n",
    "\n",
    "y_train = tr[metric]\n",
    "y_test = te[metric]\n",
    "\n",
    "model = fit_and_report_statsmodels_model(lambda y, x: sm.OLS(y, x),\n",
    "                                         sm.add_constant(X_train),\n",
    "                                         y_train,\n",
    "                                         sm.add_constant(X_test),\n",
    "                                         y_test,\n",
    "                                         \"LM No Interactions\",\n",
    "                                         transform=sm.families.links.Logit(),\n",
    "                                         inverse_transform=sm.families.links.Logit().inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f9c17-92f9-4561-9c0c-b3ae0e3153ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f72b6-66fc-49a6-959f-d153b40d642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = train_df[train_df[metric] < .99]\n",
    "te = test_df[test_df[metric] < .99]\n",
    "\n",
    "X_train = tr[ivs]\n",
    "X_test = te[ivs]\n",
    "\n",
    "y_train = tr[metric]\n",
    "y_test = te[metric]\n",
    "\n",
    "model = fit_and_report_statsmodels_model(lambda y, x: sm.GLM(y, x, family=sm.families.Binomial(link=sm.families.links.Logit())),\n",
    "                                         sm.add_constant(X_train),\n",
    "                                         y_train,\n",
    "                                         sm.add_constant(X_test),\n",
    "                                         y_test,\n",
    "                                         \"LM No Interactions\",\n",
    "                                         transform=lambda x: x,\n",
    "                                         inverse_transform=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2331a15-5223-481b-9051-fc2ffa485852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4632f5ba-bf07-4b34-b762-0e2334bc80bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcaafe15-ba5d-44bf-bb3e-f439956489d2",
   "metadata": {},
   "source": [
    "### With Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c93b22-4c62-44dc-b362-bf5389120915",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = {}\n",
    "\n",
    "features = [x for x in ivs if x not in exclude]\n",
    "\n",
    "X_train = train_df[features]\n",
    "X_tests = [x[features] for x in test_dfs]\n",
    "\n",
    "y_train = train_df[metric]\n",
    "y_tests = [x[metric] for x in test_dfs]\n",
    "\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=min_max_scaler.get_feature_names_out())\n",
    "\n",
    "poly_transform = sklearn.preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train = poly_transform.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "X_tests = [pd.DataFrame(min_max_scaler.transform(x), columns=min_max_scaler.get_feature_names_out()) for x in X_tests]\n",
    "X_tests = [poly_transform.transform(x) for x in X_tests]\n",
    "X_tests = [pd.DataFrame(x, columns=poly_transform.get_feature_names_out()) for x in X_tests]\n",
    "\n",
    "model = fit_and_report_statsmodels_model(lambda y, x: sm.GLM(y, x, family=sm.families.Binomial(link=sm.families.links.Logit())),\n",
    "                                         sm.add_constant(X_train),\n",
    "                                         y_train,\n",
    "                                         [sm.add_constant(x) for x in X_tests],\n",
    "                                         y_tests,\n",
    "                                         \"LM With Interactions\",\n",
    "                                         transform=lambda x: x,\n",
    "                                         inverse_transform=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f9a20-2055-4762-ab71-7cc4068806bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a4722c8-fd83-4a90-a319-b56d1f0fd25f",
   "metadata": {},
   "source": [
    "#### Removing Insignificant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98a5fd8-48b4-4769-9c3b-4ef1ca46febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_const = True\n",
    "\n",
    "exclude = {\n",
    "    \"r_stat_multiplier za\", # p-value\n",
    "    \"r_stat_multiplier n_craters_in_study_region\", # p-value\n",
    "    \"r_stat_multiplier areal_density\", # p-value\n",
    "    \"slope za\", # p-value\n",
    "    \"\", # p-value\n",
    "    \"\", # p-value\n",
    "    \"\", # p-value\n",
    "    \"\", # p-value\n",
    "    \"\", # p-value\n",
    "}\n",
    "\n",
    "X_train = train_df[ivs]\n",
    "X_tests = [x[ivs] for x in test_dfs]\n",
    "\n",
    "y_train = train_df[metric]\n",
    "y_tests = [x[metric] for x in test_dfs]\n",
    "\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=min_max_scaler.get_feature_names_out())\n",
    "\n",
    "poly_transform = sklearn.preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train = poly_transform.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=poly_transform.get_feature_names_out())\n",
    "X_train = X_train[[x for x in X_train.columns if x not in exclude]]\n",
    "\n",
    "X_tests = [pd.DataFrame(min_max_scaler.transform(x), columns=min_max_scaler.get_feature_names_out()) for x in X_tests]\n",
    "X_tests = [poly_transform.transform(x) for x in X_tests]\n",
    "X_tests = [pd.DataFrame(x, columns=poly_transform.get_feature_names_out()) for x in X_tests]\n",
    "X_tests = [x[[y for y in x.columns if y not in exclude]] for x in X_tests]\n",
    "\n",
    "model = fit_and_report_statsmodels_model(lambda y, x: sm.GLM(y, x, family=sm.families.Binomial(link=sm.families.links.Logit())),\n",
    "                                         sm.add_constant(X_train),\n",
    "                                         y_train,\n",
    "                                         [sm.add_constant(x) for x in X_tests],\n",
    "                                         y_tests,\n",
    "                                         \"GLM With Interactions\",\n",
    "                                         transform=lambda x: x,\n",
    "                                         inverse_transform=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57a024-08f5-4841-98c4-0aa1a800997d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a149b596-6387-40db-ac79-818665568384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b330c97-d2ff-4afe-b832-e1b8ea45a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class SMWrapper(BaseEstimator, RegressorMixin):\n",
    "    \"\"\" A universal sklearn-style wrapper for statsmodels regressors \"\"\"\n",
    "    def __init__(self, model_creator_func, fit_kwargs={}):\n",
    "        self.model_creator_func = model_creator_func\n",
    "        self.fit_kwargs = fit_kwargs\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.model_ = self.model_creator_func(y, X)\n",
    "        self.results_ = self.model_.fit(**self.fit_kwargs)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.results_.predict(X)\n",
    "    \n",
    "    @property\n",
    "    def coef_(self):\n",
    "        return self.results_.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0453a1d-c565-4421-9e18-9d3b6fce2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = {}\n",
    "\n",
    "X_train = train_df[ivs]\n",
    "X_tests = [x[ivs] for x in test_dfs]\n",
    "\n",
    "y_train = train_df[metric]\n",
    "y_tests = [x[metric] for x in test_dfs]\n",
    "\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=min_max_scaler.get_feature_names_out())\n",
    "\n",
    "poly_transform = sklearn.preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train = poly_transform.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=poly_transform.get_feature_names_out())\n",
    "X_train = X_train[[x for x in X_train.columns if x not in exclude]]\n",
    "\n",
    "X_tests = [pd.DataFrame(min_max_scaler.transform(x), columns=min_max_scaler.get_feature_names_out()) for x in X_tests]\n",
    "X_tests = [poly_transform.transform(x) for x in X_tests]\n",
    "X_tests = [pd.DataFrame(x, columns=poly_transform.get_feature_names_out()) for x in X_tests]\n",
    "X_tests = [x[[y for y in x.columns if y not in exclude]] for x in X_tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48274967-b5f3-43cf-a3b1-65934eae0607",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_features_to_select = 1 \n",
    "model = SMWrapper(lambda y, x: sm.GLM(y, x, family=sm.families.Binomial(link=sm.families.links.Logit())))\n",
    "cv = KFold(5)\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=model,\n",
    "    step=1,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    min_features_to_select=min_features_to_select,\n",
    "    n_jobs=1\n",
    ")\n",
    "rfecv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5415cb38-bc32-4a67-904d-aa627f356bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit_and_report_statsmodels_model(lambda y, x: sm.GLM(y, x, family=sm.families.Binomial(link=sm.families.links.Logit())),\n",
    "                                         sm.add_constant(X_train[rfecv.get_feature_names_out()]),\n",
    "                                         y_train,\n",
    "                                         [sm.add_constant(x[rfecv.get_feature_names_out()]) for x in X_tests],\n",
    "                                         y_tests,\n",
    "                                         \"LM With RFE Features\",\n",
    "                                         transform=lambda x: x,\n",
    "                                         inverse_transform=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbabb9a0-15cf-4015-bbef-e2582a4462d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking effect sizes\n",
    "max_coef = max([abs(x) for x, y in zip(model.params, model.params.index) if y != \"const\"])\n",
    "sorted([(abs(x / max_coef), y) for x, y in zip(model.params, model.params.index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e7e88d-b5d6-429c-b6ed-ac9adf70cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking highest p-value\n",
    "model.pvalues.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14f4f53-1a58-44d9-845c-df29450f4c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba2b9264-9b52-4ec8-adf0-1b75fd8132bc",
   "metadata": {},
   "source": [
    "### Trying a Gaussian GLM with Log Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a51a3f-ab98-4fb6-ad8f-027d56c11462",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_const = True\n",
    "\n",
    "exclude = {\n",
    "    \"effective_radius_multiplier r_stat_multiplier\", # effect size\n",
    "    \"r_stat_multiplier min_rim_percentage\", # effect size\n",
    "    \"slope r_stat_multiplier\", # effect size\n",
    "    \"r_stat_multiplier^2\", # effect size\n",
    "    \"slope effective_radius_multiplier\", # effect size\n",
    "    \"r_stat_multiplier\", # effect size\n",
    "    \"min_rim_percentage^2\", # effect size\n",
    "    \"\", # effect size\n",
    "    \"\", # effect size\n",
    "    \"\", # effect size\n",
    "}\n",
    "\n",
    "X_train = train_df[ivs]\n",
    "X_tests = [x[ivs] for x in test_dfs]\n",
    "\n",
    "y_train = train_df[metric]\n",
    "y_tests = [x[metric] for x in test_dfs]\n",
    "\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=min_max_scaler.get_feature_names_out())\n",
    "\n",
    "poly_transform = sklearn.preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train = poly_transform.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=poly_transform.get_feature_names_out())\n",
    "X_train = X_train[[x for x in X_train.columns if x not in exclude]]\n",
    "\n",
    "X_tests = [pd.DataFrame(min_max_scaler.transform(x), columns=min_max_scaler.get_feature_names_out()) for x in X_tests]\n",
    "X_tests = [poly_transform.transform(x) for x in X_tests]\n",
    "X_tests = [pd.DataFrame(x, columns=poly_transform.get_feature_names_out()) for x in X_tests]\n",
    "X_tests = [x[[y for y in x.columns if y not in exclude]] for x in X_tests]\n",
    "\n",
    "model = fit_and_report_statsmodels_model(lambda y, x: sm.OLS(y, x),\n",
    "                                         sm.add_constant(X_train),\n",
    "                                         y_train,\n",
    "                                         [sm.add_constant(x) for x in X_tests],\n",
    "                                         y_tests,\n",
    "                                         \"LM With Interactions\",\n",
    "                                         transform=sm.families.links.Logit(),\n",
    "                                         inverse_transform=sm.families.links.Logit().inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6de0ea-e230-4434-a96a-1b3ff69df06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking effect sizes\n",
    "max_coef = max([abs(x) for x, y in zip(model.params, model.params.index) if y != \"const\"])\n",
    "sorted([(abs(x / max_coef), y) for x, y in zip(model.params, model.params.index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe565d20-f169-4cfc-b02a-bb07fadbfc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking highest p-value\n",
    "model.pvalues.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be115da6-f239-41cf-971f-da5047e2dd81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9baa3aa9-3c8f-43ff-a097-3c9893e34ac5",
   "metadata": {},
   "source": [
    "### Trying Poisson GLM with log link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a372ffa-8f9e-4bb0-ad42-678281069b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_const = True\n",
    "\n",
    "exclude = {\n",
    "    \"effective_radius_multiplier r_stat_multiplier\", # effect size\n",
    "    \"r_stat_multiplier min_rim_percentage\", # effect size\n",
    "    \"slope r_stat_multiplier\", # effect size\n",
    "    \"r_stat_multiplier^2\", # effect size\n",
    "    \"slope effective_radius_multiplier\", # effect size\n",
    "    \"r_stat_multiplier\", # effect size\n",
    "    \"min_rim_percentage^2\", # effect size\n",
    "    \"\", # effect size\n",
    "    \"\", # effect size\n",
    "    \"\", # effect size\n",
    "}\n",
    "\n",
    "X_train = train_df[ivs]\n",
    "X_tests = [x[ivs] for x in test_dfs]\n",
    "\n",
    "y_train = train_df[metric]\n",
    "y_tests = [x[metric] for x in test_dfs]\n",
    "\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=min_max_scaler.get_feature_names_out())\n",
    "\n",
    "poly_transform = sklearn.preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train = poly_transform.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=poly_transform.get_feature_names_out())\n",
    "X_train = X_train[[x for x in X_train.columns if x not in exclude]]\n",
    "\n",
    "X_tests = [pd.DataFrame(min_max_scaler.transform(x), columns=min_max_scaler.get_feature_names_out()) for x in X_tests]\n",
    "X_tests = [poly_transform.transform(x) for x in X_tests]\n",
    "X_tests = [pd.DataFrame(x, columns=poly_transform.get_feature_names_out()) for x in X_tests]\n",
    "X_tests = [x[[y for y in x.columns if y not in exclude]] for x in X_tests]\n",
    "\n",
    "model = fit_and_report_statsmodels_glm_model(sm.families.Poisson(link=sm.families.links.Log()),\n",
    "                                             sm.add_constant(X_train),\n",
    "                                             y_train,\n",
    "                                             [sm.add_constant(x) for x in X_tests],\n",
    "                                             y_tests,\n",
    "                                             \"GLM With Interactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f9e8c-85d3-49e6-b668-6d224fdec287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking effect sizes\n",
    "max_coef = max([abs(x) for x, y in zip(model.params, model.params.index) if y != \"const\"])\n",
    "sorted([(abs(x / max_coef), y) for x, y in zip(model.params, model.params.index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d8dfe-71f5-4caa-b10b-fd42a6e9fc27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee4f31-b93e-4c05-a7d5-bce6496d53c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fe1d59d-551f-476a-9fdf-a1abed9f5ad8",
   "metadata": {},
   "source": [
    "### Trying with degree=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31052e41-1f9d-4292-8f71-53be9e70146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = {\n",
    "    \"slope r_stat_multiplier min_rim_percentage\", # p-value\n",
    "    \"r_stat_multiplier^2 min_rim_percentage\", # effect size\n",
    "    \"const\", # effect size\n",
    "    \"effective_radius_multiplier r_stat_multiplier min_rim_percentage\", # effect size\n",
    "    \"slope r_stat_multiplier^2\", # effect size\n",
    "    \"slope^2 r_stat_multiplier\", # effect size\n",
    "    \"slope effective_radius_multiplier r_stat_multiplier\", # effect size\n",
    "    \"\", # effect size\n",
    "    \"\", # effect size\n",
    "    \"\", # effect size\n",
    "    \"\", # effect size\n",
    "}\n",
    "\n",
    "X_train = train_df[ivs]\n",
    "X_tests = [x[ivs] for x in test_dfs]\n",
    "\n",
    "y_train = train_df[metric]\n",
    "y_tests = [x[metric] for x in test_dfs]\n",
    "\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=min_max_scaler.get_feature_names_out())\n",
    "\n",
    "poly_transform = sklearn.preprocessing.PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_train = poly_transform.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=poly_transform.get_feature_names_out())\n",
    "X_train = X_train[[x for x in X_train.columns if x not in exclude]]\n",
    "\n",
    "X_tests = [pd.DataFrame(min_max_scaler.transform(x), columns=min_max_scaler.get_feature_names_out()) for x in X_tests]\n",
    "X_tests = [poly_transform.transform(x) for x in X_tests]\n",
    "X_tests = [pd.DataFrame(x, columns=poly_transform.get_feature_names_out()) for x in X_tests]\n",
    "X_tests = [x[[y for y in x.columns if y not in exclude]] for x in X_tests]\n",
    "\n",
    "model = fit_and_report_statsmodels_model(sm.OLS,\n",
    "                                         X_train,\n",
    "                                         y_train,\n",
    "                                         X_tests,\n",
    "                                         y_tests,\n",
    "                                         \"LM With Reduced Interactions\",\n",
    "                                         transform=lambda x: x,\n",
    "                                         inverse_transform=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b16466-bc64-4ab5-a7d1-d2307fc294ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking effect sizes\n",
    "max_coef = max([abs(x) for x, y in zip(model.params, model.params.index) if y != \"const\"])\n",
    "sorted([(abs(x / max_coef), y) for x, y in zip(model.params, model.params.index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b068c-2800-45d5-8bab-064f3095a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking highest p-value\n",
    "model.pvalues.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61236200-9fb3-4f70-8598-4cf406291cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1aa9ea15-1875-475a-a359-9d3177d5ef7e",
   "metadata": {},
   "source": [
    "### Plotting Prediction Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6cf7a-9417-40ec-a7ac-37ac1d498633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_simulation_parquet(path: Path, features: list[str], sample_cadence: int) -> pd.DataFrame:\n",
    "    df = pd.read_parquet(path)\n",
    "    df = df.iloc[[x * sample_cadence + 1 for x in range(df.shape[0] // sample_cadence)]].copy()\n",
    "    df = fix_up_df(df)[features + [\"simulation_id\", \"n_craters_added_in_study_region\", metric]]\n",
    "    return df\n",
    "\n",
    "def score_model(model,\n",
    "                df: pd.DataFrame,\n",
    "                alphas: list[float],\n",
    "                features: list[str],\n",
    "                metric: str,\n",
    "                transform,\n",
    "                inverse_transform,\n",
    "                add_constant: bool) -> pd.DataFrame:\n",
    "    X = df[features]\n",
    "    X = min_max_scaler.transform(X)\n",
    "    X = pd.DataFrame(X, columns=min_max_scaler.get_feature_names_out())\n",
    "    \n",
    "    X = poly_transform.transform(X)\n",
    "    X = pd.DataFrame(X, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "    pred_df = df.reset_index(drop=True).copy()\n",
    "    pred_df = pd.concat([pred_df, X[[x for x in poly_transform.get_feature_names_out() if x not in df.columns]].copy()], axis=1)\n",
    "    # for feature_name in poly_transform.get_feature_names_out():\n",
    "    #     pred_df[feature_name] = X[feature_name]\n",
    "    \n",
    "    X = X[poly_transform.get_feature_names_out()].copy()\n",
    "    y = transform(df[metric])\n",
    "    \n",
    "    if add_constant:\n",
    "        X = sm.add_constant(X, has_constant=\"add\")\n",
    "    pred_df[\"actual\"] = list(df[metric])\n",
    "    pred_df[\"n_craters\"] = list(df.index)\n",
    "    \n",
    "    is_glm = type(model) == statsmodels.genmod.generalized_linear_model.GLMResultsWrapper\n",
    "    \n",
    "    if is_glm:\n",
    "        link = model.family.link\n",
    "        predictions = inverse_transform(model.predict(X))\n",
    "        resid = link(pred_df.actual) - link(predictions)\n",
    "        var_pred_mean = (X * np.dot(model.cov_params(), X.T).T).sum(1)\n",
    "        var_resid = resid.var()\n",
    "        sigma = np.sqrt(var_pred_mean + var_resid)\n",
    "        n = pred_df.shape[0]\n",
    "    else:\n",
    "        predictions = model.get_prediction(X)\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        if is_glm:\n",
    "            pred_df[f\"alpha_{alpha:.2f}\"] = link.inverse(link(predictions) - sigma * stats.distributions.t.ppf(1 - alpha, n - 2) * np.sqrt(1 + 1 / n))\n",
    "        else:\n",
    "            ci_lower = predictions.conf_int(obs=True, alpha=alpha*2)[:,0]\n",
    "            pred_df[f\"alpha_{alpha:.2f}\"] = inverse_transform(ci_lower)\n",
    "            pred_df[\"predicted\"] = inverse_transform(predictions.predicted)\n",
    "    \n",
    "    return pred_df\n",
    "\n",
    "\n",
    "def score_model_from_parquet_file(model,\n",
    "                                  parquet_path: Path,\n",
    "                                  sample_cadence: int,\n",
    "                                  alphas: list[float],\n",
    "                                  features: list[str],\n",
    "                                  metric: str,\n",
    "                                  transform,\n",
    "                                  inverse_transform,\n",
    "                                  add_constant: bool) -> pd.DataFrame:\n",
    "    df = read_simulation_parquet(parquet_path, features, sample_cadence)\n",
    "    return score_model(model, df, alphas, features, metric, transform, inverse_transform, add_constant)\n",
    "        \n",
    "\n",
    "def plot_sim_ci(model,\n",
    "                parquet_path: Path,\n",
    "                sample_cadence: int,\n",
    "                alphas: list[float],\n",
    "                features: list[str],\n",
    "                metric: str,\n",
    "                transform,\n",
    "                inverse_transform,\n",
    "                add_constant):\n",
    "    pred_df = score_model_from_parquet_file(model, parquet_path, sample_cadence, alphas, features, metric, transform, inverse_transform, add_constant)\n",
    "    \n",
    "    # Show params\n",
    "    print(f\"Simulation parameters: {pred_df[features].iloc[0]}\")\n",
    "\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_scatter(x=pred_df[\"n_craters\"],\n",
    "                    y=pred_df[\"actual\"],\n",
    "                    mode=\"lines\",\n",
    "                    name=\"Actual\")\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        fig.add_scatter(x=pred_df[\"n_craters\"],\n",
    "                        y=pred_df[f\"alpha_{alpha:.2f}\"],\n",
    "                        mode=\"lines\",\n",
    "                        name=f\"Pred {int(alpha*100)} Percentile\")\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"$N_G$\",\n",
    "        yaxis_title=metric\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_sim(model,\n",
    "             parquet_path: Path,\n",
    "             sample_cadence: int,\n",
    "             alphas: list[float],\n",
    "             features: List[str],\n",
    "             metric: str,\n",
    "             transform,\n",
    "             inverse_transform,\n",
    "             add_constant):\n",
    "    pred_df = score_model_from_parquet_file(model, parquet_path, sample_cadence, alphas, features, metric, transform, inverse_transform, add_constant)\n",
    "    \n",
    "    # Show params\n",
    "    print(f\"Simulation parameters: {pred_df[features].iloc[0]}\")\n",
    "    \n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_scatter(x=pred_df[\"n_craters\"],\n",
    "                    y=pred_df[\"actual\"],\n",
    "                    mode=\"lines\",\n",
    "                    name=\"Actual\")\n",
    "    \n",
    "    fig.add_scatter(x=pred_df[\"n_craters\"],\n",
    "                    y=pred_df[\"predicted\"],\n",
    "                    mode=\"lines\",\n",
    "                    name=f\"Predicted\")\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"$N_G$\",\n",
    "        yaxis_title=metric\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "def report_alphas(model,\n",
    "                  df: pd.DataFrame,\n",
    "                  alphas: list[float],\n",
    "                  features: list[str],\n",
    "                  metric: str,\n",
    "                  transform,\n",
    "                  inverse_transform,\n",
    "                  add_constant: bool):\n",
    "    pred_df = score_model(model, df, alphas, features, metric, transform, inverse_transform, add_constant)\n",
    "    \n",
    "    # Report alphas for only the last third\n",
    "    pred_df = pred_df.iloc[pred_df.shape[0] // 3 * 2:]\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        percent_below = (pred_df.actual < pred_df[f\"alpha_{alpha:.2f}\"]).mean() * 100\n",
    "        print(f\"Alpha = {alpha:.2f}, % below: {percent_below:.2f}\")\n",
    "        \n",
    "\n",
    "def report_alphas_for_parquets(model,\n",
    "                               parquet_paths: list[Path],\n",
    "                               sample_cadence: int,\n",
    "                               alphas: list[float],\n",
    "                               features: list[str],\n",
    "                               metric: str,\n",
    "                               transform,\n",
    "                               inverse_transform,\n",
    "                               add_constant: bool):\n",
    "    n_below = defaultdict(lambda: 0)\n",
    "    n = defaultdict(lambda: 0)\n",
    "    for path in parquet_paths:\n",
    "        pred_df = score_model_from_parquet_file(model, path, sample_cadence, alphas, features, metric, transform, inverse_transform, add_constant)\n",
    "        \n",
    "        for alpha in alphas:\n",
    "            n_below[alpha] += (pred_df.actual < pred_df[f\"alpha_{alpha:.2f}\"]).sum()\n",
    "            n[alpha] += pred_df.shape[0]\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        percent_below = n_below[alpha] / n[alpha] * 100\n",
    "        print(f\"Alpha = {alpha:.2f}, % below: {percent_below:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35cbf4-7f42-421b-aa22-2d5e1940b4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e74e5-3795-4574-89ad-adfbcac1c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_simulation_parquet(path: Path, sample_cadence: int) -> pd.DataFrame:\n",
    "#     df = pd.read_parquet(path)\n",
    "#     df = df.iloc[[x * sample_cadence for x in range(df.shape[0] // sample_cadence)]].copy()\n",
    "#     df = fix_up_df(df)[ivs + [\"simulation_id\", \"n_craters_added_in_study_region\", metric]]\n",
    "#     return df\n",
    "\n",
    "\n",
    "# def score_model(model,\n",
    "#                 df: pd.DataFrame,\n",
    "#                 feature_names: List[str],\n",
    "#                 metric: str,\n",
    "#                 transform,\n",
    "#                 inverse_transform,\n",
    "#                 add_constant: bool) -> pd.DataFrame:\n",
    "#     X = df[ivs]\n",
    "#     X = min_max_scaler.transform(X)\n",
    "#     X = pd.DataFrame(X, columns=min_max_scaler.get_feature_names_out())\n",
    "    \n",
    "#     X = poly_transform.transform(X)\n",
    "#     X = pd.DataFrame(X, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "#     pred_df = df.reset_index(drop=True).copy()\n",
    "#     for feature_name in poly_transform.get_feature_names_out():\n",
    "#         pred_df[feature_name] = X[feature_name]\n",
    "    \n",
    "#     X = X[feature_names].copy()\n",
    "#     y = transform(df[metric])\n",
    "    \n",
    "#     if add_constant:\n",
    "#         X = sm.add_constant(X, has_constant=\"add\")\n",
    "#     pred_df[\"actual\"] = list(df[metric])\n",
    "#     pred_df[\"n_craters\"] = list(df.index)\n",
    "#     pred_df[\"predicted\"] = list(inverse_transform(model.predict(X)))\n",
    "    \n",
    "#     return pred_df\n",
    "\n",
    "\n",
    "# def score_model_from_parquet_file(model,\n",
    "#                                   parquet_path: Path,\n",
    "#                                   sample_cadence: int,\n",
    "#                                   feature_names: List[str],\n",
    "#                                   metric: str,\n",
    "#                                   transform,\n",
    "#                                   inverse_transform,\n",
    "#                                   add_constant: bool) -> pd.DataFrame:\n",
    "#     df = read_simulation_parquet(parquet_path, sample_cadence)\n",
    "#     return score_model(model, df, feature_names, metric, transform, inverse_transform, add_constant)\n",
    "\n",
    "\n",
    "# def plot_sim_ci(model,\n",
    "#                 parquet_path: Path,\n",
    "#                 sample_cadence: int,\n",
    "#                 feature_names: List[str],\n",
    "#                 metric: str,\n",
    "#                 transform,\n",
    "#                 inverse_transform,\n",
    "#                 add_constant):\n",
    "#     pred_df = score_model_from_parquet_file(model, parquet_path, sample_cadence, feature_names, metric, transform, inverse_transform, add_constant)\n",
    "    \n",
    "#     # Show params\n",
    "#     print(f\"Simulation parameters: {pred_df[ivs].iloc[0]}\")\n",
    "\n",
    "#     ns_max = 100000\n",
    "#     plt.plot(pred_df.n_craters_added_in_study_region.iloc[:ns_max],\n",
    "#              pred_df[metric].iloc[:ns_max])\n",
    "#     plt.xlabel(\"$N_G$\")\n",
    "#     plt.ylabel(\"$Predicted$\")\n",
    "#     plt.show()\n",
    "    \n",
    "#     fig = go.Figure()\n",
    "\n",
    "#     fig.add_scatter(x=pred_df[\"n_craters\"],\n",
    "#                     y=pred_df[\"actual\"],\n",
    "#                     mode=\"lines\",\n",
    "#                     name=\"Actual\")\n",
    "    \n",
    "#     fig.add_scatter(x=pred_df[\"n_craters\"],\n",
    "#                     y=pred_df[\"predicted\"],\n",
    "#                     mode=\"lines\",\n",
    "#                     name=f\"Predicted\")\n",
    "\n",
    "#     fig.update_layout(\n",
    "#         xaxis_title=\"$N_G$\",\n",
    "#         yaxis_title=metric\n",
    "#     )\n",
    "\n",
    "#     fig.show()\n",
    "    \n",
    "\n",
    "# def plot_sim(model,\n",
    "#              parquet_path: Path,\n",
    "#              sample_cadence: int,\n",
    "#              feature_names: List[str],\n",
    "#              metric: str,\n",
    "#              transform,\n",
    "#              inverse_transform,\n",
    "#              add_constant):\n",
    "#     pred_df = score_model_from_parquet_file(model, parquet_path, sample_cadence, feature_names, metric, transform, inverse_transform, add_constant)\n",
    "    \n",
    "#     # Show params\n",
    "#     print(f\"Simulation parameters: {pred_df[ivs].iloc[0]}\")\n",
    "    \n",
    "#     fig = go.Figure()\n",
    "\n",
    "#     fig.add_scatter(x=pred_df[\"n_craters\"],\n",
    "#                     y=pred_df[\"actual\"],\n",
    "#                     mode=\"lines\",\n",
    "#                     name=\"Actual\")\n",
    "    \n",
    "#     fig.add_scatter(x=pred_df[\"n_craters\"],\n",
    "#                     y=pred_df[\"predicted\"],\n",
    "#                     mode=\"lines\",\n",
    "#                     name=f\"Predicted\")\n",
    "\n",
    "#     fig.update_layout(\n",
    "#         xaxis_title=\"$N_G$\",\n",
    "#         yaxis_title=metric\n",
    "#     )\n",
    "\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d476886-295c-49a3-9b99-6810dd5f4101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up a subset of the test DFs\n",
    "np.random.seed(123)\n",
    "\n",
    "sample_cadence = 500\n",
    "alphas = [0.01, 0.05, 0.25, 0.5]\n",
    "simulation_paths = list(Path(base_path).glob(\"simulation_*.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94d514-98c1-411f-a67a-ef9470fbe644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094b3b5-e363-4f13-9b95-4b78491ae331",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = {\n",
    "}\n",
    "\n",
    "# features = [\n",
    "#     \"slope\",\n",
    "#     \"effective_radius_multiplier\",\n",
    "#     \"r_stat_multiplier\",\n",
    "#     \"min_rim_percentage\",\n",
    "#     \"z\",\n",
    "#     \"za\",\n",
    "#     \"areal_density\",\n",
    "#     # \"areal_density_overlap_2\",\n",
    "#     \"areal_density_overlap_3\",\n",
    "#     \"center_to_center_nearest_neighbor_distance_mean\",\n",
    "#     # \"center_to_center_nearest_neighbor_distance_stdev\",\n",
    "#     # \"center_to_center_nearest_neighbor_distance_min\",\n",
    "#     # \"center_to_center_nearest_neighbor_distance_max\",\n",
    "#     \"rim_to_rim_nearest_neighbor_distance_mean\",\n",
    "#     # \"rim_to_rim_nearest_neighbor_distance_stdev\",\n",
    "#     \"rim_to_rim_nearest_neighbor_distance_max\",\n",
    "#     \"percent_rim_to_rim_nearest_neighbors_zero\"\n",
    "# ]\n",
    "features = ivs\n",
    "\n",
    "# tr = train_df[train_df[metric] < .99].reset_index()\n",
    "# te = test_df[test_df[metric] < .99].reset_index()\n",
    "\n",
    "tr = train_df.reset_index()\n",
    "te = test_df.reset_index()\n",
    "\n",
    "X_train = tr[features]\n",
    "X_test = te[features]\n",
    "\n",
    "y_train = tr[metric]\n",
    "y_test = te[metric]\n",
    "\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=min_max_scaler.get_feature_names_out())\n",
    "\n",
    "poly_transform = sklearn.preprocessing.PolynomialFeatures(degree=1, include_bias=False)\n",
    "X_train = poly_transform.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "X_test = pd.DataFrame(min_max_scaler.transform(X_test), columns=min_max_scaler.get_feature_names_out())\n",
    "X_test = poly_transform.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=poly_transform.get_feature_names_out())\n",
    "\n",
    "# model = fit_and_report_statsmodels_model(lambda y, x: sm.GLM(y, x, family=sm.families.Binomial(link=sm.families.links.Logit())),\n",
    "#                                          sm.add_constant(X_train),\n",
    "#                                          y_train,\n",
    "#                                          [sm.add_constant(x) for x in X_tests],\n",
    "#                                          y_tests,\n",
    "#                                          \"LM With Interactions\",\n",
    "#                                          transform=lambda x: x,\n",
    "#                                          inverse_transform=lambda x: x)\n",
    "\n",
    "# model = fit_and_report_statsmodels_model(lambda y, x: sm.OLS(y, x),\n",
    "#                                          sm.add_constant(X_train),\n",
    "#                                          y_train,\n",
    "#                                          [sm.add_constant(x) for x in X_tests],\n",
    "#                                          y_tests,\n",
    "#                                          \"LM No Interactions\",\n",
    "#                                          transform=sm.families.links.Logit(),\n",
    "#                                          inverse_transform=sm.families.links.Logit().inverse)\n",
    "\n",
    "# model = fit_and_report_statsmodels_model(lambda y, x: BetaModel(y, x),\n",
    "#                                          (X_train),\n",
    "#                                          y_train,\n",
    "#                                          (X_test),\n",
    "#                                          y_test,\n",
    "#                                          \"LM No Interactions\",\n",
    "#                                          transform=lambda x: x,\n",
    "#                                          inverse_transform=lambda x: x)\n",
    "\n",
    "transform = lambda x: x\n",
    "inverse_transform = lambda x: x\n",
    "\n",
    "model = fit_and_report_statsmodels_model(lambda y, x: sm.OLS(y, x),\n",
    "                                         sm.add_constant(X_train),\n",
    "                                         y_train,\n",
    "                                         sm.add_constant(X_test),\n",
    "                                         y_test,\n",
    "                                         \"LM No Interactions\",\n",
    "                                         transform=transform,\n",
    "                                         inverse_transform=inverse_transform)\n",
    "\n",
    "\n",
    "# transform = sm.families.links.Logit()\n",
    "# inverse_transform = sm.families.links.Logit().inverse\n",
    "\n",
    "# model = fit_and_report_statsmodels_model(lambda y, x: sm.OLS(y, x),\n",
    "#                                          sm.add_constant(X_train),\n",
    "#                                          y_train,\n",
    "#                                          sm.add_constant(X_test),\n",
    "#                                          y_test,\n",
    "#                                          \"LM No Interactions\",\n",
    "#                                          transform=transform,\n",
    "#                                          inverse_transform=inverse_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9b593-7a43-4b2f-a2b7-11e30be313b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_alphas(model, train_df, alphas, features, metric, transform=transform, inverse_transform=inverse_transform, add_constant=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e2a87-8a80-4a36-b7fb-456dd52a2c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_alphas(model, test_df, alphas, features, metric, transform=transform, inverse_transform=inverse_transform, add_constant=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b23d29-fee4-48a8-a74a-513a8c894ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_alphas_for_parquets(model, simulation_paths[:100], sample_cadence, alphas, features, metric, transform=transform, inverse_transform=inverse_transform, add_constant=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dcd41f-5bbd-445b-80ca-20a63937382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CIs for a few in-CCD simulations\n",
    "for x in range(10, 15):\n",
    "    print(x)\n",
    "    plot_sim(model, simulation_paths[x], 100, alphas, features, metric, transform=transform, inverse_transform=inverse_transform, add_constant=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf86a21-cc8e-41c2-8e5c-77acfeb1a261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize CIs for a few simulations\n",
    "for x in range(10, 15):\n",
    "    print(x)\n",
    "    plot_sim_ci(model, simulation_paths[x], sample_cadence, alphas, features, metric, transform=transform, inverse_transform=inverse_transform, add_constant=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c667523-7960-4a2b-9db5-8f3fd993ba8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b1e26d-95a7-43b2-9a6d-71a67e65a31f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

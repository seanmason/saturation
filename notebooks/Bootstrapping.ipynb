{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cis_overlap(ci1, ci2) -> bool:\n",
    "    return (ci2.low <= ci1.low <= ci2.high) or (ci1.low <= ci2.low <= ci1.high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500\n",
    "n_sets = 50\n",
    "n_resamples = 1000\n",
    "n_repetitions = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Distribution Equality Using a CI of the Bootstrapped KS Statistic\n",
    "\n",
    "We sample from two distributions, $A$ and $B$, and attempt to bootstrap a CI on the KS statistic.\n",
    "\n",
    "Let $X_{A,i}$ be a vector of N samples from distribution A, for $i \\in \\{1..N_{sets}\\}$. \"A\" is a stand-in for Python simulation code, \"B\" for the IDL. The \"sets\" are a stand-in for simulation runs.\n",
    "\n",
    "Let $K_{j,k}$ be the KS statistic applied to sample vectors j and k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1\n",
    "\n",
    "This is one method that was suggested in our call. I am not entirely sure it is implemented as described. The expectation is that, since sets of samples are from the same distribution, the test would confirm that the distributions are equivalent.\n",
    "\n",
    "A and B ~ N(0,1)\n",
    "\n",
    "We bootstrap two 95% confidence intervals: \n",
    "\n",
    "$CI_1$ is constructed by sampling from $K_{j,k}, \\forall j \\in X_{A,i}, \\forall k \\in X_{A,i}$\n",
    "\n",
    "$CI_2$ is constructed by sampling from $K_{j,k}, \\forall j \\in X_{B,i}, \\forall k \\in X_{B,i}$\n",
    "\n",
    "We run this process repeatedly, and find that the CIs overlap in 31% of trials. This does not appear to be successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for x in range(n_repetitions):\n",
    "    X_A = [np.random.normal(loc=0.0, scale=1.0, size=n_samples) for x in range(n_sets)]\n",
    "    X_B = [np.random.normal(loc=0.0, scale=1.0, size=n_samples) for x in range(n_sets)]\n",
    "\n",
    "    # Calculate KS statistics for all X_A and X_B, reshape for use in bootstrapping\n",
    "    KS_A_A = np.expand_dims([stats.kstest(x, y).statistic for x in X_A for y in X_A], axis=0)\n",
    "    KS_B_B = np.expand_dims([stats.kstest(x, y).statistic for x in X_B for y in X_B], axis=0)\n",
    "\n",
    "    # Bootstrap two CIs\n",
    "    CI_A_A = stats.bootstrap(KS_A_A, np.mean, n_resamples=n_resamples).confidence_interval\n",
    "    CI_B_B = stats.bootstrap(KS_B_B, np.mean, n_resamples=n_resamples).confidence_interval\n",
    "\n",
    "    # Test for overlap of the CIs\n",
    "    results.append(cis_overlap(CI_A_A, CI_B_B))\n",
    "\n",
    "np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2\n",
    "\n",
    "This is a method that I came up with that seems, to me, to be valid. If it is not, please help me to understand why.\n",
    "\n",
    "A and B ~ N(0,1)\n",
    "\n",
    "Let $P_{j,k}$ be the p-values resulting from the KS test $\\forall j \\in X_{A,i}, \\forall k \\in X_{A,i}$ \n",
    "\n",
    "We construct a 95% confidence interval by sampling from $P_{j,k}$\n",
    "\n",
    "The resulting CI is (0.27, 0.29), suggesting that that the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kstest_pvalue(x, y, axis):\n",
    "    return stats.kstest(x, y).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "X_A = np.random.normal(loc=0.0, scale=1.0, size=n_sets*n_samples)\n",
    "X_B = np.random.normal(loc=0.0, scale=1.0, size=n_sets*n_samples)\n",
    "\n",
    "CI_P_A_B = stats.bootstrap((X_A, X_B), np.vectorize(kstest_pvalue, signature=\"(n),(n),()->()\"), paired=True, batch=5, n_resamples=n_resamples).confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfidenceInterval(low=0.8865468169185391, high=0.9562510246586273)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CI_P_A_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConfidenceInterval(low=0.006607370669901561, high=0.9469108928980675)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "X_A = np.hstack([np.random.normal(loc=x, scale=1.0, size=n_samples//5) for x in np.random.normal(loc=0.0, scale=0.05, size=n_sets)])\n",
    "X_B = np.hstack([np.random.normal(loc=x, scale=1.0, size=n_samples//5) for x in np.random.normal(loc=0.0, scale=0.03, size=n_sets)])\n",
    "\n",
    "CI_P_A_B = stats.bootstrap((X_A, X_B), np.vectorize(kstest_pvalue, signature=\"(n),(n),()->()\"), paired=True, batch=5, n_resamples=n_resamples).confidence_interval\n",
    "CI_P_A_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: A ~ N(0, 1), B ~ N(1, 1)\n",
    "\n",
    "We repeat the process from Test 1 and find that the CIs overlap in 35% of trials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for x in range(n_repetitions):\n",
    "    X_A = [np.random.normal(loc=0.0, scale=1.0, size=n_samples) for x in range(n_sets)]\n",
    "    X_B = [np.random.normal(loc=1.0, scale=1.0, size=n_samples) for x in range(n_sets)]\n",
    "\n",
    "    # Calculate KS statistics for all X_A and X_B, reshape for use in bootstrapping\n",
    "    KS_A_A = np.expand_dims([stats.kstest(x, y).statistic for x in X_A for y in X_A], axis=0)\n",
    "    KS_B_B = np.expand_dims([stats.kstest(x, y).statistic for x in X_B for y in X_B], axis=0)\n",
    "\n",
    "    # Bootstrap two CIs\n",
    "    CI_A_A = stats.bootstrap(KS_A_A, np.mean, n_resamples=n_resamples).confidence_interval\n",
    "    CI_B_B = stats.bootstrap(KS_B_B, np.mean, n_resamples=n_resamples).confidence_interval\n",
    "\n",
    "    # Test for overlap of the CIs\n",
    "    results.append(cis_overlap(CI_A_A, CI_B_B))\n",
    "\n",
    "np.mean(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: A ~ N(0, 1), B ~ N(1, 2)\n",
    "\n",
    "We repeat the process from Test 1 and find that the CIs overlap in 25% of trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for x in range(n_repetitions):\n",
    "    X_A = [np.random.normal(loc=0.0, scale=1.0, size=n_samples) for x in range(n_sets)]\n",
    "    X_B = [np.random.normal(loc=1.0, scale=2.0, size=n_samples) for x in range(n_sets)]\n",
    "\n",
    "    # Calculate KS statistics for all X_A and X_B, reshape for use in bootstrapping\n",
    "    KS_A_A = np.expand_dims([stats.kstest(x, y).statistic for x in X_A for y in X_A], axis=0)\n",
    "    KS_B_B = np.expand_dims([stats.kstest(x, y).statistic for x in X_B for y in X_B], axis=0)\n",
    "\n",
    "    # Bootstrap two CIs\n",
    "    CI_A_A = stats.bootstrap(KS_A_A, np.mean, n_resamples=n_resamples).confidence_interval\n",
    "    CI_B_B = stats.bootstrap(KS_B_B, np.mean, n_resamples=n_resamples).confidence_interval\n",
    "\n",
    "    # Test for overlap of the CIs\n",
    "    results.append(cis_overlap(CI_A_A, CI_B_B))\n",
    "\n",
    "np.mean(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-joined pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing cross-joined to within set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for x in range(n_repetitions):\n",
    "    X_A = [np.random.normal(loc=0.0, scale=1.0, size=n_samples) for x in range(n_sets)]\n",
    "    X_B = [np.random.normal(loc=0.0, scale=1.0, size=n_samples) for x in range(n_sets)]\n",
    "\n",
    "    # Calculate KS statistics for all X_A and X_B, reshape for use in bootstrapping\n",
    "    KS_A_B = np.expand_dims([stats.kstest(x, y).statistic for x in X_A for y in X_B], axis=0)\n",
    "    KS_B_B = np.expand_dims([stats.kstest(x, y).statistic for x in X_B for y in X_B], axis=0)\n",
    "\n",
    "    # Bootstrap two CIs\n",
    "    CI_A_B = stats.bootstrap(KS_A_B, np.mean, n_resamples=n_resamples).confidence_interval\n",
    "    CI_B_B = stats.bootstrap(KS_B_B, np.mean, n_resamples=n_resamples).confidence_interval\n",
    "\n",
    "    # Test for overlap of the CIs\n",
    "    results.append(cis_overlap(CI_A_B, CI_B_B))\n",
    "\n",
    "np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for x in range(n_repetitions):\n",
    "    X_A = [np.random.normal(loc=0.0, scale=1.0, size=n_samples) for x in range(n_sets)]\n",
    "    X_B = [np.random.normal(loc=1.0, scale=1.0, size=n_samples) for x in range(n_sets)]\n",
    "\n",
    "    # Calculate KS statistics for all X_A and X_B, reshape for use in bootstrapping\n",
    "    KS_A_B = np.expand_dims([stats.kstest(x, y).statistic for x in X_A for y in X_B], axis=0)\n",
    "    KS_B_B = np.expand_dims([stats.kstest(x, y).statistic for x in X_B for y in X_B], axis=0)\n",
    "\n",
    "    # Bootstrap two CIs\n",
    "    CI_A_B = stats.bootstrap(KS_A_B, np.mean, n_resamples=n_resamples).confidence_interval\n",
    "    CI_B_B = stats.bootstrap(KS_B_B, np.mean, n_resamples=n_resamples).confidence_interval\n",
    "\n",
    "    # Test for overlap of the CIs\n",
    "    results.append(cis_overlap(CI_A_B, CI_B_B))\n",
    "\n",
    "np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for x in range(n_repetitions):\n",
    "    X_A = [np.random.normal(loc=0.0, scale=1.0, size=n_samples) for x in range(n_sets)]\n",
    "    X_B = [np.random.normal(loc=1.0, scale=1.0, size=n_samples) for x in range(n_sets)]\n",
    "\n",
    "    # Calculate KS statistics for all X_A and X_B, reshape for use in bootstrapping\n",
    "    KS_A_B = np.expand_dims([stats.kstest(x, y).statistic for x in X_A for y in X_B], axis=0)\n",
    "    KS_B_B = np.expand_dims([stats.kstest(x, y).statistic for x in X_B for y in X_B], axis=0)\n",
    "\n",
    "    # Bootstrap two CIs\n",
    "    CI_A_B = stats.bootstrap(KS_A_B, np.mean, n_resamples=n_resamples).confidence_interval\n",
    "    CI_B_B = stats.bootstrap(KS_B_B, np.mean, n_resamples=n_resamples).confidence_interval\n",
    "\n",
    "    # Test for overlap of the CIs\n",
    "    results.append(cis_overlap(CI_A_B, CI_B_B))\n",
    "    if x % 5 == 0:\n",
    "        print(np.mean(results))\n",
    "\n",
    "np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500\n",
    "n_sets = 50\n",
    "\n",
    "set1 = [np.random.normal(scale=1.0, size=n_samples) for x in range(n_sets)]\n",
    "set2 = [np.random.normal(scale=1.0, size=n_samples) for x in range(n_sets)]\n",
    "\n",
    "all_pairs_ks_set1 = [stats.kstest(x, y).statistic for x in set1 for y in set2]\n",
    "all_pairs_ks_set2 = [stats.kstest(x, y).statistic for x in set1 for y in set1]\n",
    "\n",
    "ci_set1 = stats.bootstrap(np.array(all_pairs_ks_set1).reshape((1, len(all_pairs_ks_set1))), np.mean, n_resamples=10000)\n",
    "ci_set2 = stats.bootstrap(np.array(all_pairs_ks_set2).reshape((1, len(all_pairs_ks_set2))), np.mean, n_resamples=10000)\n",
    "\n",
    "cis_overlap(ci_set1.confidence_interval, ci_set2.confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing unequal means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500\n",
    "n_sets = 50\n",
    "\n",
    "set1 = [np.random.normal(scale=1.0, size=n_samples) + 1 for x in range(n_sets)]\n",
    "set2 = [np.random.normal(scale=1.0, size=n_samples) for x in range(n_sets)]\n",
    "\n",
    "all_pairs_ks_set1 = [stats.kstest(x, y).statistic for x in set1 for y in set2]\n",
    "all_pairs_ks_set2 = [stats.kstest(x, y).statistic for x in set1 for y in set1]\n",
    "\n",
    "ci_set1 = stats.bootstrap(np.array(all_pairs_ks_set1).reshape((1, len(all_pairs_ks_set1))), np.mean, n_resamples=10000)\n",
    "ci_set2 = stats.bootstrap(np.array(all_pairs_ks_set2).reshape((1, len(all_pairs_ks_set2))), np.mean, n_resamples=10000)\n",
    "\n",
    "cis_overlap(ci_set1.confidence_interval, ci_set2.confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing unequal variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500\n",
    "n_sets = 50\n",
    "\n",
    "set1 = [np.random.normal(scale=1.5, size=n_samples) for x in range(n_sets)]\n",
    "set2 = [np.random.normal(scale=1.0, size=n_samples) for x in range(n_sets)]\n",
    "\n",
    "all_pairs_ks_set1 = [stats.kstest(x, y).statistic for x in set1 for y in set2]\n",
    "all_pairs_ks_set2 = [stats.kstest(x, y).statistic for x in set1 for y in set1]\n",
    "\n",
    "ci_set1 = stats.bootstrap(np.array(all_pairs_ks_set1).reshape((1, len(all_pairs_ks_set1))), np.mean, n_resamples=10000)\n",
    "ci_set2 = stats.bootstrap(np.array(all_pairs_ks_set2).reshape((1, len(all_pairs_ks_set2))), np.mean, n_resamples=10000)\n",
    "\n",
    "cis_overlap(ci_set1.confidence_interval, ci_set2.confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = parsed_df[((parsed_df.fully_successful == 1) | (parsed_df.partially_successful == 1))]\n",
    "parsed_df[\"document_text\"] = filtered.pagewise_text.str.join(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a6f5ee9b0917027ae13a32f52a26ed1a060c33dca2b3355708509e59ccb8c9f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

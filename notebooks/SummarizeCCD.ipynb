{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34fb5b29-5fdb-4d6c-bc8c-9728b34e51c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import yaml\n",
    "from typing import *\n",
    "from functools import reduce\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession, DataFrame, Row, Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b36eff61-ec11-42d5-ada4-3c9c7c3586fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/data/saturation/central_composite_design/ccd5\"\n",
    "n_cores = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "489393ae-5872-4a8b-a8ac-551df0a6d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(path: Path) -> Dict:\n",
    "    with path.open(\"r\") as config_file:\n",
    "        config = yaml.safe_load(config_file)\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_aggregations_for_column(col: str) -> Iterable:\n",
    "    # Percentiles 5 to 95 step 5\n",
    "    for quantile in range(1, 20):\n",
    "        yield F.percentile_approx(col, quantile / 20, accuracy=int(1e6)).alias(f\"{col}_{quantile*5:.0f}_percentile\")\n",
    "    \n",
    "    yield F.percentile_approx(col, .99, accuracy=int(1e6)).alias(f\"{col}_99_percentile\")\n",
    "    yield F.percentile_approx(col, .50, accuracy=int(1e6)).alias(f\"{col}_median\")\n",
    "    yield F.min(col).alias(f\"{col}_min\")\n",
    "    yield F.max(col).alias(f\"{col}_max\")\n",
    "    yield F.mean(col).alias(f\"{col}_mean\")\n",
    "    yield F.stddev_samp(col).alias(f\"{col}_stdev\")   \n",
    "    \n",
    "\n",
    "def calculate_stats(data: DataFrame) -> DataFrame:\n",
    "    # Number of craters from the end of the simulation to consider as in saturation\n",
    "    N_CRATERS_IN_SATURATION = 50000\n",
    "    \n",
    "    columns_to_calculate_stats = [\n",
    "        \"areal_density\",\n",
    "        \"z\",\n",
    "        \"za\",\n",
    "        \"n_craters_in_study_region\",\n",
    "        \"n_craters_added_in_study_region\"\n",
    "    ]\n",
    "    \n",
    "    # Grab the last N_CRATERS_IN_SATURATION craters from each simulation\n",
    "    window = Window.partitionBy(\"simulation_id\").orderBy(F.col(\"n_craters_added_in_study_region\").desc())\n",
    "    last_n_craters_by_sim = data.withColumn(\"row_number\", F.row_number().over(window)) \\\n",
    "        .filter(F.col(\"row_number\") <= 50) \\\n",
    "        .drop(\"row_number\")\n",
    "\n",
    "    # Set up the aggregations for each column of interest\n",
    "    aggregations = [\n",
    "        aggregation\n",
    "        for col in columns_to_calculate_stats\n",
    "        for aggregation in get_aggregations_for_column(col)\n",
    "    ]\n",
    "\n",
    "    return last_n_craters_by_sim.groupBy(\"simulation_id\").agg(*aggregations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "628fdb7b-c860-4871-98c6-aefdac2cb9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/31 19:24:22 WARN Utils: Your hostname, muninn resolves to a loopback address: 127.0.1.1; using 192.168.86.20 instead (on interface enp8s0)\n",
      "23/01/31 19:24:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/31 19:24:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/01/31 19:24:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .master(f\"local[{n_cores}]\") \\\n",
    "                    .appName(\"Saturation\") \\\n",
    "                    .config(\"spark.driver.memory\", \"48g\") \\\n",
    "                    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02ea8e9-fefa-4df1-9c5d-d1bc4e83be49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>effective_radius_multiplier</th>\n",
       "      <th>max_crater_radius</th>\n",
       "      <th>min_crater_radius</th>\n",
       "      <th>min_rim_percentage</th>\n",
       "      <th>output_path</th>\n",
       "      <th>r_stat_multiplier</th>\n",
       "      <th>simulation_id</th>\n",
       "      <th>simulation_name</th>\n",
       "      <th>slope</th>\n",
       "      <th>spatial_hash_cell_size</th>\n",
       "      <th>stop_condition</th>\n",
       "      <th>study_region_padding</th>\n",
       "      <th>study_region_size</th>\n",
       "      <th>write_crater_removals_cadence</th>\n",
       "      <th>write_craters_cadence</th>\n",
       "      <th>write_image_cadence</th>\n",
       "      <th>write_state_cadence</th>\n",
       "      <th>write_statistics_cadence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.901652</td>\n",
       "      <td>2500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.504785</td>\n",
       "      <td>/data/saturation/central_composite_design/ccd5...</td>\n",
       "      <td>2.999645</td>\n",
       "      <td>18</td>\n",
       "      <td>ccd_1.902_0.505_3.000_1.103</td>\n",
       "      <td>1.103217</td>\n",
       "      <td>50</td>\n",
       "      <td>{'name': None, 'min_craters': 500000, 'percent...</td>\n",
       "      <td>1250</td>\n",
       "      <td>10000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.102979</td>\n",
       "      <td>2500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.498455</td>\n",
       "      <td>/data/saturation/central_composite_design/ccd5...</td>\n",
       "      <td>9.003282</td>\n",
       "      <td>146</td>\n",
       "      <td>ccd_1.103_0.498_9.003_2.047</td>\n",
       "      <td>2.046712</td>\n",
       "      <td>50</td>\n",
       "      <td>{'name': None, 'min_craters': 500000, 'percent...</td>\n",
       "      <td>1250</td>\n",
       "      <td>10000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.901115</td>\n",
       "      <td>2500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.502025</td>\n",
       "      <td>/data/saturation/central_composite_design/ccd5...</td>\n",
       "      <td>6.015037</td>\n",
       "      <td>44</td>\n",
       "      <td>ccd_1.901_0.502_6.015_1.093</td>\n",
       "      <td>1.093015</td>\n",
       "      <td>50</td>\n",
       "      <td>{'name': None, 'min_craters': 500000, 'percent...</td>\n",
       "      <td>1250</td>\n",
       "      <td>10000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.094694</td>\n",
       "      <td>2500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.697573</td>\n",
       "      <td>/data/saturation/central_composite_design/ccd5...</td>\n",
       "      <td>3.012605</td>\n",
       "      <td>102</td>\n",
       "      <td>ccd_1.095_0.698_3.013_2.062</td>\n",
       "      <td>2.061580</td>\n",
       "      <td>50</td>\n",
       "      <td>{'name': None, 'min_craters': 500000, 'percent...</td>\n",
       "      <td>1250</td>\n",
       "      <td>10000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.100000</td>\n",
       "      <td>2500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>/data/saturation/central_composite_design/ccd5...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>145</td>\n",
       "      <td>ccd_1.100_0.500_9.000_2.050</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>50</td>\n",
       "      <td>{'name': None, 'min_craters': 500000, 'percent...</td>\n",
       "      <td>1250</td>\n",
       "      <td>10000</td>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   effective_radius_multiplier  max_crater_radius  min_crater_radius  \\\n",
       "0                     1.901652               2500                 10   \n",
       "1                     1.102979               2500                 10   \n",
       "2                     1.901115               2500                 10   \n",
       "3                     1.094694               2500                 10   \n",
       "4                     1.100000               2500                 10   \n",
       "\n",
       "   min_rim_percentage                                        output_path  \\\n",
       "0            0.504785  /data/saturation/central_composite_design/ccd5...   \n",
       "1            0.498455  /data/saturation/central_composite_design/ccd5...   \n",
       "2            0.502025  /data/saturation/central_composite_design/ccd5...   \n",
       "3            0.697573  /data/saturation/central_composite_design/ccd5...   \n",
       "4            0.500000  /data/saturation/central_composite_design/ccd5...   \n",
       "\n",
       "   r_stat_multiplier  simulation_id              simulation_name     slope  \\\n",
       "0           2.999645             18  ccd_1.902_0.505_3.000_1.103  1.103217   \n",
       "1           9.003282            146  ccd_1.103_0.498_9.003_2.047  2.046712   \n",
       "2           6.015037             44  ccd_1.901_0.502_6.015_1.093  1.093015   \n",
       "3           3.012605            102  ccd_1.095_0.698_3.013_2.062  2.061580   \n",
       "4           9.000000            145  ccd_1.100_0.500_9.000_2.050  2.050000   \n",
       "\n",
       "   spatial_hash_cell_size                                     stop_condition  \\\n",
       "0                      50  {'name': None, 'min_craters': 500000, 'percent...   \n",
       "1                      50  {'name': None, 'min_craters': 500000, 'percent...   \n",
       "2                      50  {'name': None, 'min_craters': 500000, 'percent...   \n",
       "3                      50  {'name': None, 'min_craters': 500000, 'percent...   \n",
       "4                      50  {'name': None, 'min_craters': 500000, 'percent...   \n",
       "\n",
       "   study_region_padding  study_region_size  write_crater_removals_cadence  \\\n",
       "0                  1250              10000                         100000   \n",
       "1                  1250              10000                         100000   \n",
       "2                  1250              10000                         100000   \n",
       "3                  1250              10000                         100000   \n",
       "4                  1250              10000                         100000   \n",
       "\n",
       "   write_craters_cadence  write_image_cadence  write_state_cadence  \\\n",
       "0                 100000                10000                    0   \n",
       "1                 100000                10000                    0   \n",
       "2                 100000                10000                    0   \n",
       "3                 100000                10000                    0   \n",
       "4                 100000                10000                    0   \n",
       "\n",
       "   write_statistics_cadence  \n",
       "0                    100000  \n",
       "1                    100000  \n",
       "2                    100000  \n",
       "3                    100000  \n",
       "4                    100000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read configs\n",
    "completed_filenames = list(Path(base_path).glob(\"*/completed.txt\"))\n",
    "configs = map(lambda x: x.parent / \"config.yaml\", completed_filenames)\n",
    "configs = map(read_config, configs)\n",
    "configs = sc.parallelize(configs).toDF()\n",
    "\n",
    "configs.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c89064-9f9d-4b58-bfd4-e74d1451d6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read statistics\n",
    "stats_df = spark.read.parquet(f\"{base_path}/*/statistics_*.parquet\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a94471b-e77b-416d-a819-2e7a4898e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = calculate_stats(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ef05905-c1b7-4ae2-bda9-360e161d5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_filenames = list(Path(base_path).glob(\"*/completed.txt\"))\n",
    "configs = map(lambda x: x.parent / \"config.yaml\", completed_filenames)\n",
    "configs = map(read_config, configs)\n",
    "configs = sc.parallelize(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea7d26a-eae5-46e9-a2e5-cb8213df0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_columns = [\n",
    "    \"simulation_id\",\n",
    "    \"slope\",\n",
    "    \"r_stat_multiplier\",\n",
    "    \"effective_radius_multiplier\",\n",
    "    \"min_rim_percentage\"\n",
    "]\n",
    "configs_df = configs.toDF().select(config_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed6b11e-40cd-4017-bfb0-e1675bd56f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = configs_df.join(data, on=\"simulation_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0a47855-0336-4b1b-acbb-26754ac5fced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write out the result\n",
    "joined.toPandas().to_csv(f\"{base_path}/post_saturation_statistics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f125784-7250-461c-b364-c42798271e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0831c3b-8b45-422b-b33f-3df2da26510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a dataframe with all data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc85d54-693d-44d8-8ab1-9a1eac76b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(path: Path) -> Dict:\n",
    "    with path.open(\"r\") as config_file:\n",
    "        config = yaml.safe_load(config_file)\n",
    "    return config\n",
    "\n",
    "\n",
    "def calculate_stats(data: DataFrame) -> DataFrame:\n",
    "    columns_to_calculate_stats = [\n",
    "        \"areal_density\",\n",
    "        \"z\",\n",
    "        \"za\",\n",
    "        \"n_craters_in_study_region\",\n",
    "        \"n_craters_added_in_study_region\"\n",
    "    ]\n",
    "    \n",
    "    # Grab the last N_CRATERS_IN_SATURATION craters from each simulation\n",
    "    window = Window.partitionBy(\"simulation_id\").orderBy(F.col(\"n_craters_added_in_study_region\").desc())\n",
    "    last_n_craters_by_sim = data.withColumn(\"row_number\", F.row_number().over(window)) \\\n",
    "        .filter(F.col(\"row_number\") <= N_CRATERS_IN_SATURATION) \\\n",
    "        .drop(\"row_number\")\n",
    "\n",
    "    # Set up the aggregations for each column of interest\n",
    "    aggregations = [\n",
    "        aggregation\n",
    "        for col in columns_to_calculate_stats\n",
    "        for aggregation in get_aggregations_for_column(col)\n",
    "    ]\n",
    "\n",
    "    return last_n_craters_by_sim.groupBy(\"simulation_id\").agg(*aggregations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c800e6-33e9-4ed9-b21e-6889133930dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac8c36d-34ae-44f3-9e91-a92fa1ff3fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756ea9b2-fe7a-41a5-a1f1-dc11881cd44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afb4a61e-9af1-40fc-8aed-255bac0c73cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a post-saturation sample from each simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b48108ca-f791-477f-9492-8c85363839c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(path: Path) -> Dict:\n",
    "    with path.open(\"r\") as config_file:\n",
    "        config = yaml.safe_load(config_file)\n",
    "    return config\n",
    "\n",
    "def read_configs(base_path: str) -> pyspark.RDD:\n",
    "    completed_filenames = list(Path(base_path).glob(\"*/completed.txt\"))\n",
    "    configs = map(lambda x: x.parent / \"config.yaml\", completed_filenames)\n",
    "    configs = map(read_config, configs)\n",
    "    return sc.parallelize(configs)\n",
    "\n",
    "def create_configs_df(configs: pyspark.RDD) -> DataFrame:\n",
    "    config_columns = [\n",
    "        \"simulation_id\",\n",
    "        \"slope\",\n",
    "        \"r_stat_multiplier\",\n",
    "        \"effective_radius_multiplier\",\n",
    "        \"min_rim_percentage\"\n",
    "    ]\n",
    "    return configs.toDF().select(config_columns)\n",
    "\n",
    "def sample_by_simulation(data: DataFrame,\n",
    "                         configs: pyspark.RDD,\n",
    "                         n_craters_in_saturation: int,\n",
    "                         n_craters_to_sample: int) -> DataFrame:\n",
    "    configs_df = create_configs_df(configs)\n",
    "    \n",
    "    window = Window.partitionBy(\"simulation_id\").orderBy(F.col(\"n_craters_added_in_study_region\").desc())\n",
    "    last_n_craters_by_sim = data.withColumn(\"row_number\", F.row_number().over(window)) \\\n",
    "        .filter(F.col(\"row_number\") <= n_craters_in_saturation) \\\n",
    "        .drop(\"row_number\") \\\n",
    "        .cache()\n",
    "    \n",
    "    fractions = {\n",
    "        x.simulation_id: n_craters_to_sample / n_craters_in_saturation\n",
    "        for x in last_n_craters_by_sim.select(\"simulation_id\").distinct().collect()\n",
    "    }\n",
    "    sample_df = last_n_craters_by_sim.sampleBy(\"simulation_id\", fractions=fractions, seed=0)\n",
    "    \n",
    "    return configs_df.join(sample_df, on=\"simulation_id\")\n",
    "\n",
    "def save_holdout_simulations(holdout_simulations: DataFrame,\n",
    "                             holdout_simulation_ids: Iterable[int],\n",
    "                             configs: pyspark.RDD) -> None:\n",
    "    configs_df = create_configs_df(configs)\n",
    "    \n",
    "    for holdout_simulation_id in holdout_simulation_ids:\n",
    "        filtered = holdout_simulations.filter(F.col(\"simulation_id\") == holdout_simulation_id)\n",
    "        joined = configs_df.join(filtered, on=\"simulation_id\")\n",
    "        joined.toPandas().to_parquet(f\"{base_path}/simulation_{holdout_simulation_id}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d5ed5541-19c2-4b81-9390-740538c343f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/07 18:02:54 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "holdout_simulation_ids = {x * 9 + 4 for x in range(27)}\n",
    "\n",
    "stats_df = spark.read.parquet(f\"{base_path}/*/statistics_*.parquet\").cache()\n",
    "holdout_simulations = stats_df.filter(F.col(\"simulation_id\").isin(holdout_simulation_ids))\n",
    "model_simulations = stats_df.filter(~F.col(\"simulation_id\").isin(holdout_simulation_ids))\n",
    "configs = read_configs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44c751bc-3bed-4059-a052-8cb4ebb5f94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sample = sample_by_simulation(model_simulations, configs, 50000, 5000)\n",
    "sample.toPandas().to_csv(f\"{base_path}/post_saturation_sample_5000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6000d4b-4922-4545-87f7-067acde5338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_holdout_simulations(holdout_simulations, holdout_simulation_ids, configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8983a3-ed15-46bb-96cd-a147a7056ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
